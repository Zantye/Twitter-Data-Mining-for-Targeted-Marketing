{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "afford.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VirtualGoat/Twitter-Data-Mining/blob/master/afford.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt7TgZ-phyA2",
        "colab_type": "code",
        "outputId": "6bd7cdb2-3951-465f-c2eb-2d609b93adc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "!pip install GetOldTweets3\n",
        "#Using GOT module as twitter's official API restrict the tweets to a specific number thus preventing the user to download old tweets(> 2 months)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GetOldTweets3\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from GetOldTweets3) (4.2.6)\n",
            "Collecting pyquery>=1.2.10\n",
            "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
            "Collecting cssselect>0.7.9\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Installing collected packages: cssselect, pyquery, GetOldTweets3\n",
            "Successfully installed GetOldTweets3-0.0.11 cssselect-1.1.0 pyquery-1.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gd7tuBL3XIC",
        "colab_type": "code",
        "outputId": "69c4518a-b9cf-403a-d8a6-7bbafd607548",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Accessing the data that has been stored. \n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import GetOldTweets3 as got\n",
        "drive.mount('/content/drive')\n",
        "DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/Internship/Usernames/Mumbai\"\n",
        "users4=open(DATA_PATH+'/slot3.pickle','rb')\n",
        "real_tweets3=pickle.load(users4)\n",
        "users4.close()\n",
        "print(len(real_tweets3))\n",
        "lisi=list()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "672\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2HRRcxd4Jyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users5=open(DATA_PATH+'/slot3.pickle','wb')\n",
        "real_tweets4=pickle.dump(list(real_tweets3),users5)\n",
        "users5.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdrAZ2Y0zIxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import multiprocessing \n",
        "#Using multiprocessing as it utilizes all the cores of CPU and enables parallel computing. \n",
        "crawled=set() #unique elements can only be stored. \n",
        "m = multiprocessing.Manager()\n",
        "q = m.Queue()\n",
        "for i in real_tweets3[5:7]:      \n",
        "    q.put(i)\n",
        "print(q.qsize())\n",
        "li=list()\n",
        "\n",
        "'''\n",
        "Steps for checking: \n",
        "--> The usernames have been put in a queue. \n",
        "--> Each process will access the usernames and pull the tweet data fo the usernames. \n",
        "--> To prevent multiple processes from accessing the same username, te username will be popped once a process accepts the username.\n",
        "'''\n",
        "def check_if_rich(q):  \n",
        "  keywords=['singapore','america','spain','germany','france','paris','berlin','europe','bali','indonesia','switzerland','australia','malaysia','united kingdom','london','mauritius','maldives','thailand','dubai','netherland','tokyo','japan','canada','new york','california','fransisco','angeles','vegas','miami','florida','usa','bermuda','iceland','denmark','luxembourg','kuwait','hong kong','greece','mercedes','bmw','lexus','jaguar','royce','fortuner','audi','bentley','porsche','ferrari','volvo','triumph','enfield','interceptor','rover','cadillac','maserati','lamborghini','hilfiger','rolex','rado','tissot','giordano','diesel','fossil','guess','kors','calvin klein','heuer','armani','adidas','nike','piguet','blanc','hublot','patek', 'bandra', 'khar', 'mahalaxmi', 'south bombay', 'worli', 'vashi', 'colaba','dadar','malabar','lokhandwala','andheri','powai','juhu','peddar','altamount','parel', 'trident','marriot','itc','oberoi','taj','hyatt','lalit','sahara','four seasons','westin','orchid','kohinoor','fariyas','marine plaza','meluha','rodas','radisson','shalimar','waterstones','ambassador','ramada','mirage']\n",
        "  while(q.empty()!=True): #Repeat until queue contains some elements. \n",
        "    try:\n",
        "        uname=q.get()     #Queue does not contain unique usernames so a separate set is used to store the crawled usernames \n",
        "        print(uname)\n",
        "        if uname not in crawled:\n",
        "            crawled.add(uname)\n",
        "            tweetCriteria = got.manager.TweetCriteria().setUsername(uname).setSince(\"2019-01-01\").setUntil(\"2019-12-31\") #Pull yearly tweets\n",
        "            tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "            print(\"Crawling User: \",uname)      \n",
        "            for j in tweets:\n",
        "                if any(word in ((j.text).lower()).split() for word in keywords):  #Checking for the presence of qualifying keywords in tweets.  \n",
        "                    li.append(uname)\n",
        "                    print(li)\n",
        "                    print(j.text)\n",
        "                    break\n",
        "            print(\"Going for next user.\")\n",
        "    except:\n",
        "      continue\n",
        "  return li\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvXeT-wVrDR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from concurrent.futures import ProcessPoolExecutor\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "# with concurrent.futures.ProcessPoolExecutor(7) as executor:\n",
        "#     future = executor.submit(check_if_rich, q)\n",
        "#     return_value = future.result()\n",
        "\n",
        "\n",
        "\n",
        "pool = ProcessPoolExecutor(4)\n",
        " \n",
        "future = pool.submit(check_if_rich, q)\n",
        "result=future.result()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import tweepy\n",
        "\n",
        "consumer_key=''\n",
        "consumer_secret= ''\n",
        "access_token=''\n",
        "access_token_secret=''\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "\n",
        "pname=list()\n",
        "for i in result:\n",
        "    try:\n",
        "      u=api.get_user(i)\n",
        "      pname.append(u.name)\n",
        "    except:\n",
        "      continue\n",
        "print(\"Extracted Usernames: \",pname)\n",
        "\n",
        "\n",
        "import string\n",
        "import re\n",
        "def clean_tweet(tweet): \n",
        "    ''' \n",
        "    Use sumple regex statemnents to clean tweet text by removing links and special characters\n",
        "    '''\n",
        "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t]) \\\n",
        "                                |(\\w+:\\/\\/\\S+)\", \" \", tweet).split()) \n",
        "def deEmojify(text):\n",
        "    '''\n",
        "    Strip all non-ASCII characters to remove emoji characters\n",
        "    '''\n",
        "    if text:\n",
        "        return text.encode('ascii', 'ignore').decode('ascii')\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "clean=list()\n",
        "\n",
        "mail=['gmail','yahoo','hotmail','rediff']\n",
        "\n",
        "#Check if email id is mentioned as profile name or else clean the profile name\n",
        "for i in pname:\n",
        "  if (any(word in i.lower() for word in mail))==True:  \n",
        "      clean.append(i.lower())    \n",
        "  else:\n",
        "      demo=deEmojify(i)\n",
        "      cle=clean_tweet(demo)\n",
        "      cleaned=cle.translate(str.maketrans(string.punctuation, ' '*len(string.punctuation)))\n",
        "      clean.append(cleaned)\n",
        "\n",
        "print(\"After cleaning: \",clean)\n",
        "\n",
        "\n",
        "\n",
        "no=['decor','realt','digi','acre','resid','stock','group','article','project','commerc','brick','india','guru','new','market', \\\n",
        "    'enterp','vastu','astro','estate','mall','hous','mumbai','sky','room','home','flat','design','interior','furniture','trend', \\\n",
        "    'pack','build','work','propert','vastu','gym','loan','luxury','bloomberg','business','direct','time',\\\n",
        "    'revenue','day','bank','agen','job','minis','corpo','tech', \\\n",
        "    'boss','nation','associat','developer','broth','invest','people','dna','media','break','bombay','lodha','hiranandani']\n",
        "finalset=set()\n",
        "for i in clean:\n",
        "    if any(word in i.lower() for word in no):\n",
        "        finalset.add(i)\n",
        "\n",
        "users=set(clean)\n",
        "h=users-finalset\n",
        "print(\"After last cleaning: \",h)\n",
        "\n",
        "\n",
        "\n",
        "import string\n",
        "import time\n",
        "import threading\n",
        "import urllib\n",
        "import re\n",
        "import io\n",
        "import sys\n",
        "from time import sleep\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def formats(first, middle, last, domain):\n",
        "    \"\"\"\n",
        "    Create a list of 30 possible email formats combining:\n",
        "    - First name:          [empty] | Full | Initial |\n",
        "    - Delimitator:         [empty] |   .  |    _    |    -\n",
        "    - Last name:           [empty] | Full | Initial |\n",
        "    \"\"\"\n",
        "    list = []\n",
        "    emails=['gmail','yahoo','rediff','hotmail']\n",
        "\n",
        "    if any(word in first for word in emails):\n",
        "        list.append(first)\n",
        "\n",
        "    elif any(word in middle for word in emails):\n",
        "        list.append(middle)\n",
        "\n",
        "    elif any(word in last for word in emails):\n",
        "        list.append(last)\n",
        "\n",
        "\n",
        "    elif len(last)==0:\n",
        "        list.append(first + '@' + domain)                    # first@example.com\n",
        "\n",
        "\n",
        "    else:\n",
        "        list.append(first[0] + last + '@' + domain)          # flast@example.com\n",
        "        list.append(first[0] + '.' + last + '@' + domain)    # f.last@example.com\n",
        "        list.append(first[0] + '_' + last + '@' + domain)    # f_last@example.com\n",
        "        list.append(first + '@' + domain)                    # first@example.com\n",
        "        list.append(first + last + '@' + domain)             # firstlast@example.com\n",
        "        list.append(first + '.' + last + '@' + domain)       # first.last@example.com\n",
        "        list.append(first + '_' + last + '@' + domain)       # first_last@example.com\n",
        "        list.append(first + '-' + last + '@' + domain)       # first-last@example.com\n",
        "\n",
        "        list.append(first + last[0] + '@' + domain)          # fistl@example.com\n",
        "        list.append(first + '.' + last[0] + '@' + domain)    # first.l@example.com\n",
        "        list.append(first + '_' + last[0] + '@' + domain)    # fist_l@example.com\n",
        "        \n",
        "        list.append(first[0] + middle + last + '@' + domain)          # fmiddlelast@example.com\n",
        "        list.append(first[0] + '.' + middle + last + '@' + domain)    # f.middlelast@example.com\n",
        "        list.append(first[0] + middle + '.' + last + '@' + domain)    # fmiddle.last@example.com\n",
        "        list.append(first[0] + '_' + middle+ last + '@' + domain)    # f_middlelast@example.com\n",
        "        list.append(first[0] + middle +'_' + last + '@' + domain)    # fmiddle_last@example.com\n",
        "        list.append(first + middle+ last + '@' + domain)             # firstmiddlelast@example.com\n",
        "        list.append(first + middle + '.' + last + '@' + domain)       # firstmiddle.last@example.com\n",
        "        list.append(first + '.' + middle + last + '@' + domain)       # first.middlelast@example.com\n",
        "        list.append(first + '_' + middle + last + '@' + domain)       # first_last@example.com\n",
        "        list.append(first + middle + '_' + last + '@' + domain)       # first_last@example.com\n",
        "        list.append(first + middle+ last[0] + '@' + domain)          # firstmiddlel@example.com\n",
        "        list.append(first + '.' + middle +last[0] + '@' + domain)    # first.middlel@example.com\n",
        "        list.append(first + middle + '.' +last[0] + '@' + domain)    # firstmiddle.l@example.com\n",
        "        list.append(first + '_' + middle +last[0] + '@' + domain)    # first_middlel@example.com\n",
        "        list.append(first + middle +'_' + last[0] + '@' + domain)    # firstmiddle_l@example.com        \n",
        "        \n",
        "        list.append(last + '@' + domain)                     # last@example.com\n",
        "        list.append(last + first+ '@' + domain)              # lastfirst@example.com\n",
        "        list.append(last + '.' + first + '@' + domain)       # last.first@example.com\n",
        "        list.append(last + '_' + first + '@' + domain)       # last_first@example.com\n",
        "        list.append(last[0] + '.' + first + '@' + domain)    # l.first@example.com    \n",
        "        list.append(last[0] + first + '@' + domain)          # lfirst@example.com\n",
        "        list.append(last + first[0] + '@' + domain)          # lastf@example.com\n",
        "        list.append(last + '.' + first[0] + '@' + domain)    # last.f@example.com\n",
        "        list.append(last + '_' + first[0] + '@' + domain)    # last_f@example.com\n",
        "       \n",
        "    return(list)\n",
        "\n",
        "\n",
        "\n",
        "len2=list()\n",
        "l1=list()\n",
        "l3=list()\n",
        "ln=list()\n",
        "\n",
        "email_list=list()\n",
        "emails=['gmail.com','yahoo.com','rediff.com','hotmail.com','yahoo.co.in']\n",
        "for j in emails:\n",
        "    for i in h:\n",
        "        try:\n",
        "            i=i.lower()\n",
        "            s=i.split()\n",
        "\n",
        "            if len(s)==2:\n",
        "                email_list.extend(formats(s[0],'',s[1],j))\n",
        "                len2.append(i)\n",
        "            elif len(s)==1:\n",
        "                email_list.extend(formats(s[0],'','',j))        \n",
        "                l1.append(i)\n",
        "            elif len(s)==3:\n",
        "                email_list.extend(formats(s[0],s[1],s[2],j))    \n",
        "                l3.append(i)\n",
        "            elif len(s)>3:\n",
        "                ln.append(i)\n",
        "                continue    \n",
        "        except:\n",
        "            continue        \n",
        "    lisi.extend(email_list)\n",
        "print(len(lisi))\n",
        "\n",
        "emails1=set(lisi)\n",
        "print(len(emails1))\n",
        "\n",
        "ninoo=list(emails1)\n",
        "nino1=pd.Series(ninoo)\n",
        "\n",
        "nino1.to_csv(\"/content/drive/My Drive/Colab Notebooks/Internship/Usernames/Mumbai/slot3_0to336.csv\",index=False,encoding='UTF-8')\n",
        "\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}